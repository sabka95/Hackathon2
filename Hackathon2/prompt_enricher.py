# Importation de la biblioth√®que Hugging Face Transformers
from transformers import pipeline

# Chargement d‚Äôune pipeline de g√©n√©ration de texte √† partir de texte
# Le mod√®le utilis√© ici est 'google/flan-t5-base', un LLM polyvalent optimis√© pour suivre des instructions
generator = pipeline("text2text-generation", model="google/flan-t5-base")

# Fonction d‚Äôenrichissement de prompt : elle rend le prompt plus descriptif pour g√©n√©rer une image plus d√©taill√©e
def enrich_prompt(prompt: str) -> str:
    """
    Utilise un LLM pour enrichir le prompt utilisateur en ajoutant des d√©tails visuels.
    
    Args:
        prompt (str): prompt de base saisi par l'utilisateur (ex : "a red bird")

    Returns:
        str: prompt enrichi (ex : "a vivid red bird with long feathers flying over a misty forest")
    """
    
    # Cr√©ation d‚Äôune instruction claire pour guider le LLM (en anglais car les mod√®les Flan-T5 sont anglophones)
    instruction = f"Make this prompt much more detailed and visual for an image generator: '{prompt}'"
    
    # Appel de la pipeline de g√©n√©ration de texte
    result = generator(
        instruction,
        max_new_tokens=30,              # Longueur maximale de la r√©ponse g√©n√©r√©e
        do_sample=False,             # D√©sactivation du sampling pour une r√©ponse plus d√©terministe
        num_return_sequences=1,      # On ne garde qu‚Äôune seule version du prompt enrichi
    )[0]['generated_text']
    print("üîç R√©sultat g√©n√©r√© :", result)
    # Nettoyage et retour du texte enrichi
    return result.strip()
